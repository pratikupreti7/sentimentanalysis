{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torchSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9B0lN-RoK5bv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c6f68147-2fca-4431-805e-9413a1fc2dd2"
      },
      "source": [
        "!git clone https://github.com/lukysummer/Movie-Review-Sentiment-Analysis-LSTM-Pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Movie-Review-Sentiment-Analysis-LSTM-Pytorch'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jdp_xdOLL0uo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a129c15f-a32a-4652-b439-e529061bd66f"
      },
      "source": [
        "!ls Movie-Review-Sentiment-Analysis-LSTM-Pytorch/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt  reviews.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mcrcB2ovK1IQ",
        "colab": {}
      },
      "source": [
        "with open(\"Movie-Review-Sentiment-Analysis-LSTM-Pytorch/data/reviews.txt\") as f:\n",
        "    reviews = f.read()\n",
        "    \n",
        "with open(\"/Movie-Review-Sentiment-Analysis-LSTM-Pytorch/data/labels.txt\") as f:\n",
        "    labels = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xqjDiBxuK1Iw",
        "colab": {}
      },
      "source": [
        "from string import punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UcDXBfM6K1I5",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([ch for ch in text if ch not in punctuation])\n",
        "    all_reviews = text.split(\"\\n\")\n",
        "    text = \" \".join(text)\n",
        "    all_words = text.split()\n",
        "    \n",
        "    return all_reviews, all_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yRXfxUXVK1JB",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eMrSD-g4K1JJ",
        "colab": {}
      },
      "source": [
        "all_reviews, all_words = preprocess(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AxxQYnOqK1JR",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brVAT3hNK1JZ",
        "colab": {}
      },
      "source": [
        "word_counts = Counter(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6uibuq0BK1Ji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ae481e43-e7a3-4e06-cbde-bd25d27567c7"
      },
      "source": [
        "word_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'b': 515850,\n",
              "         'r': 1550946,\n",
              "         'o': 1922852,\n",
              "         'm': 709785,\n",
              "         'w': 509705,\n",
              "         'e': 3086458,\n",
              "         'l': 1143358,\n",
              "         ' ': 7434318,\n",
              "         'h': 1408705,\n",
              "         'i': 1984336,\n",
              "         'g': 537842,\n",
              "         's': 1754598,\n",
              "         'a': 2082813,\n",
              "         'c': 720691,\n",
              "         't': 2420932,\n",
              "         'n': 1705883,\n",
              "         'd': 906473,\n",
              "         'y': 533174,\n",
              "         '.': 327192,\n",
              "         'p': 441581,\n",
              "         'u': 687982,\n",
              "         'f': 572095,\n",
              "         'v': 326565,\n",
              "         'k': 223823,\n",
              "         'x': 43360,\n",
              "         '\\n': 25000,\n",
              "         'z': 23095,\n",
              "         'j': 58707,\n",
              "         'q': 20148})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EM48ASOLK1Jt",
        "colab": {}
      },
      "source": [
        "word_list = sorted(word_counts, key = word_counts.get, reverse = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQw4NozISf68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6UEjmQLmK1J_",
        "colab": {}
      },
      "source": [
        "vocab_to_int = {word:idx for idx, word in enumerate(word_list)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-N159tnZK1KH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "f9fee5d1-8416-4545-f293-d7a13016699e"
      },
      "source": [
        "vocab_to_int"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'e': 1,\n",
              " 't': 2,\n",
              " 'a': 3,\n",
              " 'i': 4,\n",
              " 'o': 5,\n",
              " 's': 6,\n",
              " 'n': 7,\n",
              " 'r': 8,\n",
              " 'h': 9,\n",
              " 'l': 10,\n",
              " 'd': 11,\n",
              " 'c': 12,\n",
              " 'm': 13,\n",
              " 'u': 14,\n",
              " 'f': 15,\n",
              " 'g': 16,\n",
              " 'y': 17,\n",
              " 'b': 18,\n",
              " 'w': 19,\n",
              " 'p': 20,\n",
              " '.': 21,\n",
              " 'v': 22,\n",
              " 'k': 23,\n",
              " 'j': 24,\n",
              " 'x': 25,\n",
              " '\\n': 26,\n",
              " 'z': 27,\n",
              " 'q': 28}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NMyQ2MDrK1KS",
        "colab": {}
      },
      "source": [
        "int_to_vocab = {idx:word for word, idx in vocab_to_int.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I5kuUX_SK1KZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "7afe5f5e-d154-4b29-e151-014833fb8cc1"
      },
      "source": [
        "int_to_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: 'e',\n",
              " 2: 't',\n",
              " 3: 'a',\n",
              " 4: 'i',\n",
              " 5: 'o',\n",
              " 6: 's',\n",
              " 7: 'n',\n",
              " 8: 'r',\n",
              " 9: 'h',\n",
              " 10: 'l',\n",
              " 11: 'd',\n",
              " 12: 'c',\n",
              " 13: 'm',\n",
              " 14: 'u',\n",
              " 15: 'f',\n",
              " 16: 'g',\n",
              " 17: 'y',\n",
              " 18: 'b',\n",
              " 19: 'w',\n",
              " 20: 'p',\n",
              " 21: '.',\n",
              " 22: 'v',\n",
              " 23: 'k',\n",
              " 24: 'j',\n",
              " 25: 'x',\n",
              " 26: '\\n',\n",
              " 27: 'z',\n",
              " 28: 'q'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iLbbtZQvK1Ki",
        "colab": {}
      },
      "source": [
        "encoded_reviews = [[vocab_to_int[word] for word in review] for review in all_reviews]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SabhkmGbK1Ko",
        "colab": {}
      },
      "source": [
        "# encoded_reviews = []\n",
        "# i = 0\n",
        "# for review in all_reviews:\n",
        "#     curr_rev = []\n",
        "#     for letter in review:\n",
        "#         if letter==\" \":\n",
        "#             continue\n",
        "#         curr_rev.append(vocab_to_int[letter])\n",
        "#     encoded_reviews.append(letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peH1RpxSSf8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels = labels.split(\"\\n\")\n",
        "encoded_labels = [1 if label == \"positive\" else 0 for label in all_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOGaflCGSf8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yoH8K0_OK1LX",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RaVxnxjLK1Lg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anFffKx-K1Ln",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kzfXNCyFK1Lr",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RMDSO1TuK1Ly",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nCHVhnPK1L3",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xBC5b1RK1L7",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jKjvNNU-K1MD",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MT4jrjSOK1MJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_bCir_jK1MP",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qCRMDXK4K1MW",
        "colab": {}
      },
      "source": [
        "encoded_labels = np.array( [label for idx, label in enumerate(encoded_labels) if len(encoded_reviews[idx]) > 0] )\n",
        "encoded_reviews = [review for review in encoded_reviews if len(review) > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bDYLJ63Sf9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_text(encoded_reviews, seq_length):\n",
        "    \n",
        "    reviews = []\n",
        "    \n",
        "    for review in encoded_reviews:\n",
        "        if len(review) >= seq_length:\n",
        "            reviews.append(review[:seq_length])\n",
        "        else:\n",
        "            reviews.append([0]*(seq_length-len(review)) + review)\n",
        "        \n",
        "    return np.array(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnQOJ0oFSf9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_reviews = pad_text(encoded_reviews, seq_length = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlRBb5LuSf9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratio = 0.8\n",
        "valid_ratio = (1 - train_ratio)/2\n",
        "total = padded_reviews.shape[0]\n",
        "train_cutoff = int(total * train_ratio)\n",
        "valid_cutoff = int(total * (1 - valid_ratio))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbe10saKSf9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, train_y = padded_reviews[:train_cutoff], encoded_labels[:train_cutoff]\n",
        "valid_x, valid_y = padded_reviews[train_cutoff : valid_cutoff], encoded_labels[train_cutoff : valid_cutoff]\n",
        "test_x, test_y   = padded_reviews[valid_cutoff:], encoded_labels[valid_cutoff:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10hPTqWiSf90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = torch.Tensor(train_x).type(torch.LongTensor)\n",
        "train_y = torch.Tensor(train_y).type(torch.LongTensor)\n",
        "valid_x = torch.Tensor(valid_x).type(torch.LongTensor)\n",
        "valid_y = torch.Tensor(valid_y).type(torch.LongTensor)\n",
        "test_x  = torch.Tensor(test_x).type(torch.LongTensor)\n",
        "test_y  = torch.Tensor(test_y).type(torch.LongTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDxdReYtSf94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBibCl5PSf99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(train_x, train_y)\n",
        "valid_data = TensorDataset(valid_x, valid_y)\n",
        "test_data = TensorDataset(test_x, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6b6KPT2Sf-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 25\n",
        "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS8e2pSrSf-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqy6BB-iSf-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiCx4JQuSf-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z83iHlrISf-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p = 0.5):\n",
        "        super().__init__()\n",
        "        # params: \"n_\" means dimension\n",
        "        self.n_vocab = n_vocab     # number of unique words in vocabulary\n",
        "        self.n_layers = n_layers   # number of LSTM layers \n",
        "        self.n_hidden = n_hidden   # number of hidden nodes in LSTM\n",
        "        \n",
        "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
        "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, dropout = drop_p)\n",
        "        self.dropout = nn.Dropout(drop_p)\n",
        "        self.fc = nn.Linear(n_hidden, n_output)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward (self, input_words, h):\n",
        "        \n",
        "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
        "        lstm_out, h = self.lstm(embedded_words, h)         # (batch_size, seq_length, n_hidden)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden) # (batch_size*seq_length, n_hidden)\n",
        "        fc_out = self.fc(lstm_out)                      # (batch_size*seq_length, n_output)\n",
        "        sigmoid_out = self.sigmoid(fc_out)              # (batch_size*seq_length, n_output)\n",
        "        sigmoid_out = sigmoid_out.view(batch_size, -1)  # (batch_size, seq_length*n_output)\n",
        "        \n",
        "        # extract the output of ONLY the LAST output of the LAST element of the sequence\n",
        "        sigmoid_last = sigmoid_out[:, -1]               # (batch_size, 1)\n",
        "        \n",
        "        return sigmoid_last, h\n",
        "    \n",
        "    \n",
        "    def init_hidden (self, batch_size):  # initialize hidden weights (h,c) to 0\n",
        "        \n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        device = \"cpu\"\n",
        "        weights = next(self.parameters()).data\n",
        "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
        "             weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
        "        \n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW38odl0Sf-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMQsazLwSf-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_vocab = len(vocab_to_int)+1\n",
        "n_embed = 400\n",
        "n_hidden = 512\n",
        "n_output = 1   # 1 (\"positive\") or 0 (\"negative\")\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Pt-RypSf-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCK_b4u_Sf-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEa7uLkMSf-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_every = 100\n",
        "step = 0\n",
        "n_epochs = 4  # validation loss increases from ~ epoch 3 or 4\n",
        "clip = 5  # for gradient clip to prevent exploding gradient problem in LSTM/RNN\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMW2O-6fSf-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # making requires_grad = False for the latest set of h\n",
        "        h = tuple([each.data for each in h])   \n",
        "        \n",
        "        net.zero_grad()\n",
        "        output, h = net(inputs)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (step % print_every) == 0:            \n",
        "            ######################\n",
        "            ##### VALIDATION #####\n",
        "            ######################\n",
        "            net.eval()\n",
        "            valid_losses = []\n",
        "            v_h = net.init_hidden(batch_size)\n",
        "            \n",
        "            for v_inputs, v_labels in valid_loader:\n",
        "                v_inputs, v_labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "                v_h = tuple([each.data for each in v_h])\n",
        "                \n",
        "                v_output, v_h = net(v_inputs)\n",
        "                v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
        "                valid_losses.append(v_loss.item())\n",
        "\n",
        "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
        "                  \"Step: {}\".format(step),\n",
        "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
        "                  \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
        "            net.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx48fvadSf-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv4xyxnVSf-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH4jD8drSf-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjvRlg77Sf--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuj95Ep3Sf_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AoQNS56Sf_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApP4BSWHSf_J",
        "colab_type": "code",
        "colab": {},
        "outputId": "bf3c1b39-3a0e-462a-dcb8-aed4ce844ea9"
      },
      "source": [
        "net.eval()\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "test_h = net.init_hidden(batch_size)\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "    test_output, test_h = net(inputs, test_h)\n",
        "    loss = criterion(test_output, labels)\n",
        "    test_losses.append(loss.item())\n",
        "    \n",
        "    preds = torch.round(test_output.squeeze())\n",
        "    correct_tensor = preds.eq(labels.float().view_as(preds))\n",
        "    correct = np.squeeze(correct_tensor.numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    \n",
        "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
        "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-50c942d7ce6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-25b1381ebdd6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_words, h)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0membedded_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_words\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# (batch_size, seq_length, n_embed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# (batch_size, seq_length, n_hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size*seq_length, n_hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    526\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fDbyUSkSf_M",
        "colab_type": "code",
        "colab": {},
        "outputId": "63ab6cb4-9449-48ad-aadb-babe0f760b7b"
      },
      "source": [
        "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
        "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: nan\n",
            "Test Accuracy: 0.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3256: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/lib/python3.8/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyHxtzBRSf_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = preprocess(\"It made me cry.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ2WHMKdSf_U",
        "colab_type": "code",
        "colab": {},
        "outputId": "1e4f8d48-80cb-4b19-9ad9-9500068559ed"
      },
      "source": [
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['it made me cry'], ['i', 't', 'm', 'a', 'd', 'e', 'm', 'e', 'c', 'r', 'y'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_R8R4G4Sf_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_words = [vocab_to_int[word] for word in words[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1VvtR_oSf_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, review, seq_length = 200):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    device = \"cpu\"\n",
        "    words = preprocess(review)\n",
        "    encoded_words = [vocab_to_int[word] for word in words[1]]\n",
        "    padded_words = pad_text([encoded_words], seq_length)\n",
        "    padded_words = torch.from_numpy(padded_words).to(device)\n",
        "    \n",
        "    if(len(padded_words) == 0):\n",
        "        \"Your review must contain at least 1 word!\"\n",
        "        return None\n",
        "    \n",
        "    net.eval()\n",
        "    h = net.init_hidden(1)\n",
        "    output, h = net(padded_words, h)\n",
        "    pred = (output.squeeze())\n",
        "    msg = \"This is a positive review.\" if pred[0] == 0 else \"This is a negative review.\"\n",
        "    \n",
        "    return msg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN-kOU13Sf_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVmw7tkBSf_h",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1597a4f-951b-4de9-c2fd-4fbc43850985"
      },
      "source": [
        "review1 = \"It made me cry.\"\n",
        "predict(net, review1)  ## negative ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a negative review.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Vp_FH3Sf_k",
        "colab_type": "code",
        "colab": {},
        "outputId": "ba20990a-f3b6-48d4-d843-105d9d6f4161"
      },
      "source": [
        "review2 = \"It was so good it made me cry.\"\n",
        "predict(net, review2)  ## positive ##"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a negative review.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmHhXD29Sf_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review3 = \"It's ok.\"\n",
        "predict(net, review3)  ## negative ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gPl5KRGSf_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review4 = \"This movie had the best acting and the dialogue was so good. I loved it.\"\n",
        "predict(net, review4)  ## positive ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAfATyjbSf_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review5 = \"Garbage\"\n",
        "predict(net, review5)  ## negative ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLfm8385Sf_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbrj76-nSf_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}